{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,FloatType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                    .appName(\"ReadCSV\")\\\n",
    "                    .master(\"local\")\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_field = [StructField(\"code\", StringType(), True),\n",
    "                 StructField(\"symbol\", StringType(), True),\n",
    "                 StructField(\"Name\", StringType(), True),\n",
    "                 StructField(\"value\",IntegerType(), True),\n",
    "                 StructField(\"_corrupt_record\", StringType(), True)]\n",
    "schema = StructType(schema_field)\n",
    "opt = {\"header\":True, \"inferSchema\":False, \"mode\":\"permissive\",\"escape\":\"\\\"\", \"nullValue\":20}\n",
    "#here escape is used to escape the comma < , > in the double qoute <\"\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\") \\\n",
    "                .options(**opt)\\\n",
    "                .schema(schema)\\\n",
    "                .load(\"currency.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+--------------------+-----+--------------------+\n",
      "|code|symbol|                Name|value|     _corrupt_record|\n",
      "+----+------+--------------------+-----+--------------------+\n",
      "| AED|   د.إ|United Arab Emira...|   10|                NULL|\n",
      "| AFN|     ؋|      Afghan afghani| NULL|AFN,؋,Afghan afgh...|\n",
      "| ALL|     L|       Albanian, lek|   30|                NULL|\n",
      "| AMD|   AMD|       Armenian dram|   40|                NULL|\n",
      "| ANG|     ƒ|Netherlands Antil...|   50|                NULL|\n",
      "| AOA|    Kz|      Angolan kwanza| NULL|                NULL|\n",
      "| ARS|     $|      Argentine peso| NULL|                NULL|\n",
      "| AUD|     $|   Australian dollar| NULL|                NULL|\n",
      "| AWG|  Afl.|       Aruban florin| NULL|                NULL|\n",
      "| AZN|   AZN|   Azerbaijani manat| NULL|                NULL|\n",
      "| BAM|    KM|Bosnia and Herzeg...| NULL|                NULL|\n",
      "| BBD|     $|    Barbadian dollar| NULL|                NULL|\n",
      "| BDT|    ৳ |    Bangladeshi taka| NULL|                NULL|\n",
      "| BGN|   лв.|       Bulgarian lev| NULL|                NULL|\n",
      "| BHD|  .د.ب|      Bahraini dinar| NULL|                NULL|\n",
      "| BIF|    Fr|     Burundian franc| NULL|                NULL|\n",
      "| BMD|     $|    Bermudian dollar| NULL|                NULL|\n",
      "| BND|     $|       Brunei dollar| NULL|                NULL|\n",
      "| BOB|   Bs.|  Bolivian boliviano| NULL|                NULL|\n",
      "| BRL|    R$|      Brazilian real| NULL|                NULL|\n",
      "+----+------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+--------------+-----+--------------------+\n",
      "|code|symbol|          Name|value|     _corrupt_record|\n",
      "+----+------+--------------+-----+--------------------+\n",
      "| AFN|     ؋|Afghan afghani| NULL|AFN,؋,Afghan afgh...|\n",
      "+----+------+--------------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"_corrupt_record\"] != 'NULL').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".spark-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
