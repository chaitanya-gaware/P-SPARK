{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType,IntegerType,FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"df_creation2\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, 'John', 25, 85.5),\n",
    "    (2, 'Alice', 30, 92.3),\n",
    "    (3, 'Bob', 28, 78.9),\n",
    "    (4, 'Charlie', 22, 95.2),\n",
    "    (5, 'David', 35, 88.7),\n",
    "    (6, 'Emma', 29, 91.0),\n",
    "    (7, 'Frank', 32, 79.5),\n",
    "    (8, 'Grace', 26, 87.2),\n",
    "    (9, 'Helen', 31, 94.1),\n",
    "    (10, 'Ivan', 24, 82.8)\n",
    "]\n",
    "\n",
    "#schema creation for the above data\n",
    "schema_field = [StructField(\"id\", IntegerType(), True),\n",
    "                StructField(\"name\", StringType(), False),\n",
    "                StructField(\"age\", IntegerType(), False),\n",
    "                StructField(\"score\", FloatType(), True)]\n",
    "schema = StructType(schema_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+----+\n",
      "| id|   name|val|val2|\n",
      "+---+-------+---+----+\n",
      "|  1|   John| 25|85.5|\n",
      "|  2|  Alice| 30|92.3|\n",
      "|  3|    Bob| 28|78.9|\n",
      "|  4|Charlie| 22|95.2|\n",
      "|  5|  David| 35|88.7|\n",
      "|  6|   Emma| 29|91.0|\n",
      "|  7|  Frank| 32|79.5|\n",
      "|  8|  Grace| 26|87.2|\n",
      "|  9|  Helen| 31|94.1|\n",
      "| 10|   Ivan| 24|82.8|\n",
      "+---+-------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import  *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"df_creation2\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"val\", IntegerType(), True),\n",
    "   StructField(\"val2\", FloatType(),True)])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [\n",
    "    (1, 'John', 25, 85.5),\n",
    "    (2, 'Alice', 30, 92.3),\n",
    "    (3, 'Bob', 28, 78.9),\n",
    "    (4, 'Charlie', 22, 95.2),\n",
    "    (5, 'David', 35, 88.7),\n",
    "    (6, 'Emma', 29, 91.0),\n",
    "    (7, 'Frank', 32, 79.5),\n",
    "    (8, 'Grace', 26, 87.2),\n",
    "    (9, 'Helen', 31, 94.1),\n",
    "    (10, 'Ivan', 24, 82.8)\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.show()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".spark-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
